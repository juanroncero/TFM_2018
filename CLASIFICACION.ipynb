{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "FASE 1: CARGA DE DATOS, TRATAMIENTO, LIMPIADO Y CREACIÓN DE DATAFRAME FINAL\n",
    "<br><br>FASE 2: ANÁLISIS VARIABLES, FEATURES SELECTION\n",
    "<br><br>FASE 3: DEFINICIÓN FUNCIONES MACHINE LEARNING Y APLICACIÓN DE MODELOS\n",
    "<br><br>FASE 4: CONCLUSIONES\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "FASE 1\n",
    "</DIV>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "LIBRERIAS\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "import math\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# SPLIT + NORMALIZADO\n",
    "#from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#METRICAS\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# REGRESORES\n",
    "#from sklearn.neighbors import KNeighborsRegressor\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "#from sklearn.datasets import load_boston, load_iris\n",
    "#from sklearn.linear_model import LinearRegression, Ridge\n",
    "#from sklearn import svm\n",
    "\n",
    "# AMBOS\n",
    "import xgboost as xgb\n",
    "\n",
    "# CLASIFICACION\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# FEATURES SELECTION\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "style.use('ggplot')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "CARGA DE DATOS\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FICHEROS ALOJADOS EN UN SERVIDOR NUESTRO: http://dreamlife.es\n",
    "ruta = \"http://dreamlife.es/ripple.csv\"\n",
    "dfTransacciones = pd.read_csv(ruta,delimiter=\";\", decimal=\",\")\n",
    "\n",
    "ruta = \"http://dreamlife.es/ballenas.csv\"\n",
    "dfTransBallenas = pd.read_csv(ruta,delimiter=\";\", decimal=\",\")\n",
    "\n",
    "ruta = \"http://dreamlife.es/tweets.csv\"\n",
    "dfTweets = pd.read_csv(ruta,delimiter=\";\", decimal=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "TRATAMIENTO DE DATOS\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORM\n",
    "dfTransacciones[\"FECHA\"] = pd.to_datetime(dfTransacciones[\"FECHA\"])\n",
    "dfTransacciones.index = pd.to_datetime(dfTransacciones[\"FECHA\"], unit='s')\n",
    "dfTransacciones = dfTransacciones.sort_values('FECHA')\n",
    "\n",
    "dfTransBallenas[\"FECHA\"] = dfTransBallenas[\"FECHA_OPERACION\"]\n",
    "dfTransBallenas[\"FECHA\"] = pd.to_datetime(dfTransBallenas[\"FECHA\"])\n",
    "dfTransBallenas.index = pd.to_datetime(dfTransBallenas[\"FECHA\"], unit='s')\n",
    "dfTransBallenas = dfTransBallenas.sort_values('FECHA')\n",
    "\n",
    "dfTweets[\"FECHA\"] = pd.to_datetime(dfTweets[\"FECHA\"])\n",
    "dfTweets.index = pd.to_datetime(dfTweets[\"FECHA\"], unit='s')\n",
    "dfTweets = dfTweets.sort_values('FECHA')\n",
    "dfTweets = dfTweets[dfTweets[\"ID_CUENTA\"]==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "VARIABLE GLOBAL USADA PARA PODER PROBAR DIFERENTES AGRUPADOS DE TIEMPO DE LOS 3 TIPOS DE DATAFRAME:\n",
    "<BR><BR>\n",
    "- Transacciones de usuarios\n",
    "<BR><BR>\n",
    "- Transacciones de ballenas (>1.000.000)\n",
    "<BR><BR>\n",
    "- Tweets\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutosDeAgrupado = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "FUNCIONES PARA AGRUPAR LOS DATAFRAMES POR TIEMPO\n",
    "<br><BR>\n",
    "(Reciben como parámetro el dataframe y el número de minutos)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupaTweets(df, minutos):\n",
    "    \n",
    "    df1 = df.groupby(pd.Grouper(key='FECHA', freq=str(minutos)  + 'Min')).mean()\n",
    "    df1 = df1[\"SENTIMIENTO\"]\n",
    "    \n",
    "    return df1\n",
    "\n",
    "def agrupaBallenas(df, minutos):\n",
    "    \n",
    "    df['CANTIDAD_TOTAL'] = df[\"CANTIDAD\"]\n",
    "        \n",
    "    df1 = df.groupby(pd.Grouper(key='FECHA', freq=str(minutos)  + 'Min')).count()\n",
    "    df1[\"NUM_TRANSACCIONES\"] = df1['CANTIDAD']\n",
    "    df1 = df1[\"NUM_TRANSACCIONES\"] \n",
    "    \n",
    "    df2 = df.groupby(pd.Grouper(key='FECHA', freq=str(minutos)  + 'Min')).sum()\n",
    "    df2 = df2['CANTIDAD_TOTAL']\n",
    "    \n",
    "    df = pd.concat([df1, df2],axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def agrupaDatos(df, minutos):\n",
    "    \n",
    "    #df = dfTransacciones\n",
    "    dfCompras = df[df[\"TIPOTRANSACCION\"]==False]\n",
    "    dfVentas = df[df[\"TIPOTRANSACCION\"]==True]\n",
    "\n",
    "    # NUEVAS COLUMNAS\n",
    "    df[\"HIGH\"] = df[\"PRICE\"]\n",
    "    df['LOW'] = df[\"PRICE\"]\n",
    "    df['CANTIDAD_TOTAL'] = df[\"AMOUNT\"]\n",
    "    dfCompras['NUM_T_COMPRA'] = dfCompras[\"AMOUNT\"]\n",
    "    dfVentas['NUM_T_VENTA'] = dfVentas[\"AMOUNT\"]\n",
    "\n",
    "    # MAXIMO, MINIMO, CANTIDAD_TOTAL\n",
    "    df1 = df.groupby(pd.Grouper(key='FECHA', freq=str(minutos)  + 'Min')).agg({'HIGH':np.max, 'LOW':np.min,'CANTIDAD_TOTAL':np.sum})\n",
    "\n",
    "    # NÚMERO DE TRANSACCIONES DE COMPRA\n",
    "    df2 = dfCompras.groupby(pd.Grouper(key='FECHA', freq=str(minutos)  + 'Min')).count()\n",
    "    df2 = df2['NUM_T_COMPRA']\n",
    "\n",
    "    # NÚMERO DE TRANSACCIONES DE VENTA\n",
    "    df3 = dfVentas.groupby(pd.Grouper(key='FECHA', freq=str(minutos)  + 'Min')).count()\n",
    "    df3 = df3['NUM_T_VENTA']\n",
    "\n",
    "    # CANTIDAD TOTAL DE MONEDA COMPRADA\n",
    "    df4 = dfCompras.groupby(pd.Grouper(key='FECHA', freq=str(minutos)  + 'Min')).sum() \n",
    "    df4[\"CANTIDAD_COMPRA\"] = df4['AMOUNT']\n",
    "    df4 = df4['CANTIDAD_COMPRA']\n",
    "\n",
    "    # CANTIDAD TOTAL DE MONEDA VENDIDA\n",
    "    df5 = dfVentas.groupby(pd.Grouper(key='FECHA', freq=str(minutos)  + 'Min')).sum()\n",
    "    df5[\"CANTIDAD_VENTA\"] = df5['AMOUNT']\n",
    "    df5 = df5['CANTIDAD_VENTA']\n",
    "\n",
    "    # OPEN\n",
    "    df6 = df.groupby(pd.Grouper(key='FECHA', freq=str(minutos)  + 'Min')).first()\n",
    "    df6[\"OPEN\"] = df6[\"PRICE\"]\n",
    "    df6= df6[\"OPEN\"]\n",
    "\n",
    "    # CLOSE\n",
    "    df7 = df.groupby(pd.Grouper(key='FECHA', freq=str(minutos)  + 'Min')).last()\n",
    "    df7[\"CLOSE\"] = df7[\"PRICE\"]\n",
    "    df7= df7[\"CLOSE\"]\n",
    "\n",
    "    df = pd.concat([df1, df2, df3, df4, df5, df6, df7], axis=1)\n",
    "\n",
    "    # NUEVAS COLUMNAS CALCULADAS\n",
    "    df['VAR_MAX'] = (df['HIGH'] - df['LOW'])/df['LOW'] * 100\n",
    "    df['VAR_INTERVALO'] = (df['CLOSE'] - df['OPEN'])/df['OPEN'] * 100\n",
    "\n",
    "    # FILTRAMOS COLUMNAS \n",
    "    df = df[['NUM_T_COMPRA','NUM_T_VENTA','CANTIDAD_COMPRA','CANTIDAD_VENTA','VAR_MAX','VAR_INTERVALO','OPEN', 'CLOSE']]\n",
    "\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "AGRUPAMOS LOS 3 DATAFRAMES\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAgrupadoUsuarios = agrupaDatos(dfTransacciones, minutosDeAgrupado)\n",
    "dfAgrupadoTweets = agrupaTweets(dfTweets, minutosDeAgrupado)\n",
    "dfAgrupadoBallenas = agrupaBallenas(dfTransBallenas, minutosDeAgrupado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "CREAMOS DOS FEATURES NUEVAS PARA MEDIR LA TENSIÓN DEL MERCADO EN EL DATAFRME DE TRANSACCIONES\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfAgrupadoUsuarios[\"TENDENCIA_SUBIDA_ACUMULADA\"] = 0 # 0-N FLOAT REGISTRA LA ACUMULACIÓN DE SUBIDA EN %\n",
    "dfAgrupadoUsuarios[\"TENDENCIA_BAJADA_ACUMULADA\"] = 0 # 0-N FLOAT REGISTRA LA ACUMULACIÓN DE BAJADA EN %\n",
    "\n",
    "numColTendenciaSubida = 8\n",
    "numColTendenciaBajada = 9\n",
    "\n",
    "acumuladoSubida = 0\n",
    "acumuladoBajada = 0\n",
    "primeraSubida = True\n",
    "primeraBajada = True\n",
    "\n",
    "cont = 0\n",
    "\n",
    "contDebugSub = 0\n",
    "contDebugBaj = 0\n",
    "\n",
    "for index, row in dfAgrupadoUsuarios.iterrows():\n",
    "       \n",
    "        # SI SUBE EL PRECIO\n",
    "        if(row['VAR_INTERVALO'] > 0):      \n",
    "            \n",
    "            contDebugSub+=1\n",
    "            \n",
    "            if(primeraSubida):\n",
    "                acumuladoBajada = 0\n",
    "                primeraBajada = True\n",
    "                primeraSubida = False\n",
    "            \n",
    "            acumuladoSubida += row['VAR_INTERVALO']\n",
    "            dfAgrupadoUsuarios.iloc[cont,numColTendenciaSubida] = acumuladoSubida                                                \n",
    "            \n",
    "        # SI BAJA EL PRECIO\n",
    "        else:             \n",
    "            \n",
    "            contDebugBaj+=1\n",
    "            \n",
    "            if(primeraBajada): \n",
    "                acumuladoSubida = 0\n",
    "                primeraSubida = True\n",
    "                primeraBajada = False\n",
    "            \n",
    "            acumuladoBajada += -row['VAR_INTERVALO']\n",
    "            dfAgrupadoUsuarios.iloc[cont,numColTendenciaBajada] = acumuladoBajada                \n",
    "           \n",
    "        cont+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "CREAMOS FEATURES NUEVAS EN FUNCIÓN DE LOS VALORES DE REGISTROS ANTERIORES\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "######### VARIABLES ENTRADA #############\n",
    "#########################################\n",
    "numeroRegAnteriores = 5\n",
    "\n",
    "dfFinal = dfAgrupadoUsuarios\n",
    "\n",
    "for i in range(1, numeroRegAnteriores+1):\n",
    "    dfAux =  dfAgrupadoUsuarios.shift(i)\n",
    "    etiqueta = '_t(' + str(i) + ')'\n",
    "    dfAux.columns = ['NUM_T_COMPRA' + etiqueta,\n",
    "                    'NUM_T_VENTA' + etiqueta,\n",
    "                    'CANTIDAD_COMPRA'  + etiqueta,\n",
    "                    'CANTIDAD_VENTA' + etiqueta, \n",
    "                    'VAR_MAX' + etiqueta,\n",
    "                    'VAR_INTERVALO' + etiqueta,\n",
    "                    'OPEN' + etiqueta,\n",
    "                    'CLOSE' + etiqueta,\n",
    "                    'TENDENCIA_SUBIDA_ACUMULADA' + etiqueta,\n",
    "                    'TENDENCIA_BAJADA_ACUMULADA' + etiqueta]\n",
    "    dfFinal = pd.concat([dfFinal, dfAux], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "CREAMOS VARIABLE A PRONOSTICAR\n",
    "<br><br>\n",
    "Ya que buscamos probar aalgoritmos de clasificacion, estableceremos la variable como 1 en caso de subida, y 0 en caso de bajada.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numIntervarlosHorizonte = 3\n",
    "\n",
    "mask = dfFinal[\"VAR_INTERVALO\"].shift(-numIntervarlosHorizonte) > 0\n",
    "dfFinal[\"PRONOSTICO\"] = 0\n",
    "dfFinal[mask]= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "FASE 2 - FEATURES SELECTION\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "2.1 Univariate Selection\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  242.916   775.723   281.988   335.157   323.72   1060.08   1394.58\n",
      "  1376.461   472.757]\n"
     ]
    }
   ],
   "source": [
    "dfTemp = dfFinal.abs()\n",
    "\n",
    "array = dfTemp.values\n",
    "X = array[:,0:9]\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "Y = array[:,9].astype('int')\n",
    "\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X, Y)\n",
    "numpy.set_printoptions(precision=3)\n",
    "\n",
    "print(fit.scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "En esta primera selección de variables, \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "2.2 Recursive Feature Elimination\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 4\n",
      "Selected Features: [ True  True  True False False  True False False False]\n",
      "Feature Ranking: [1 1 1 6 4 1 2 5 3]\n"
     ]
    }
   ],
   "source": [
    "dfTemp = dfFinal.abs()\n",
    "\n",
    "array = dfTemp.values\n",
    "X = array[:,0:9]\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "Y = array[:,9].astype('int')\n",
    "\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 4)\n",
    "fit = rfe.fit(X, Y)\n",
    "\n",
    "print(\"Num Features:\" , fit.n_features_)\n",
    "print(\"Selected Features:\", fit.support_)\n",
    "print(\"Feature Ranking:\", fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "2.3 Recursive Feature Elimination\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.017  0.043  0.033  0.021  0.228  0.304  0.15   0.12   0.084]\n"
     ]
    }
   ],
   "source": [
    "dfTemp = dfFinal.abs()\n",
    "\n",
    "array = dfTemp.values\n",
    "X = array[:,0:9]\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "Y = array[:,9].astype('int')\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "FASE 3 - MACHINE LEARNING\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "ML - FUNCIONES \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculaMetricas(y_test, y_pred):\n",
    "    \n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    return mae, mse, rmse\n",
    "     \n",
    "def mensajeAlgoritmo(start, nombre):\n",
    "    \n",
    "    segundos = time.time() - start\n",
    "    if(segundos < 1):\n",
    "          mensaje = nombre + \" PROCESADO EN < 1 seg\"\n",
    "    else:\n",
    "          mensaje = nombre + \" PROCESADO EN \" + str(time.time() - start) + \" seg.\"              \n",
    "\n",
    "    return mensaje\n",
    "\n",
    "\n",
    "# ENUMERADOR DE ALGORITMOS\n",
    "class modeloRegresion:\n",
    "    \n",
    "    # NaiveBayesClassifier\n",
    "    SGDClassifier, DecisionTreeClassifier, GradientBoostingClassifier, RandomForest, KVecinos, XGBClassifier = range(6)\n",
    "    \n",
    "def train_test_split(df, nombreColumna, test_size=0.1):\n",
    "    \n",
    "    split_row = len(df) - int(test_size * len(df))\n",
    "    train_data = df.iloc[:split_row]\n",
    "    test_data = df.iloc[split_row:]\n",
    "    \n",
    "    x_ent = np.array(train_data.drop([nombreColumna],1)) \n",
    "    #x_ent = preprocessing.scale(x_ent)\n",
    "    x_ent = preprocessing.robust_scale(x_ent)\n",
    "    x_test = np.array(test_data.drop([nombreColumna],1))\n",
    "    #x_test = preprocessing.scale(x_test)\n",
    "    x_test = preprocessing.robust_scale(x_test)\n",
    "    \n",
    "    y_ent = np.array(train_data[nombreColumna]) \n",
    "    y_test = np.array(test_data[nombreColumna]) \n",
    "    \n",
    "    return x_ent, x_test, y_ent, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "FUNCIONES DE ALGORITMOS DE MACHINE LEARNING\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerModelo(df, nombreColumnaLabel,tipo):\n",
    "    \n",
    "    x_ent, x_test, y_ent, y_test = train_test_split(df,nombreColumnaLabel,test_size=0.2)    \n",
    "\n",
    "    score = 0\n",
    "    parametros = ''\n",
    "    \n",
    "    if(tipo==modeloRegresion.SGDClassifier): \n",
    "        \n",
    "        nombre = \"SGDClassifier\"\n",
    "        modelo = SGDClassifier() \n",
    "        \n",
    "    if(tipo==modeloRegresion.DecisionTreeClassifier):                 \n",
    "        nombre = \"DecisionTreeClassifier\"     \n",
    "        \n",
    "        # CALCULAMOS EL MEJOR MODELO EN FUNCION DEL MAXDEPTH   \n",
    "        mejorParam1 = 0\n",
    "        mejorScoreTree = 0\n",
    "        \n",
    "        for i in range(1,6):\n",
    "            arbol = DecisionTreeClassifier(max_depth=i, criterion='gini')\n",
    "            arbol.fit(x_ent,y_ent)\n",
    "            score = arbol.score(x_test,y_test)\n",
    "\n",
    "            if(score > mejorScoreTree):\n",
    "                mejorScoreTree = score\n",
    "                mejorParam1 = i        \n",
    "\n",
    "        modelo = DecisionTreeClassifier(max_depth=mejorParam1, criterion='gini')\n",
    "        parametros = 'max_depth:%s' %mejorParam1\n",
    "\n",
    "    if(tipo==modeloRegresion.RandomForest): \n",
    "        \n",
    "        nombre = \"RandomForest\"\n",
    "        modelo = RandomForestClassifier(n_jobs=2, random_state=0)  \n",
    "    \n",
    "    \n",
    "    if(tipo==modeloRegresion.GradientBoostingClassifier):                 \n",
    "        \n",
    "        nombre = \"GradientBoostingClassifier\"     \n",
    "        \n",
    "        # CALCULAMOS EL MEJOR MODELO EN FUNCION DEL MAXDEPTH   \n",
    "        mejorParam1 = 0\n",
    "        mejorScoreTree = 0\n",
    "        \n",
    "        for i in range(1,10):\n",
    "            arbol = GradientBoostingClassifier(random_state=10,n_estimators=100, learning_rate=1.0, max_depth=i)\n",
    "            arbol.fit(x_ent,y_ent)\n",
    "            score = arbol.score(x_test,y_test)\n",
    "\n",
    "            if(score > mejorScoreTree):\n",
    "                mejorScoreTree = score\n",
    "                mejorParam1 = i        \n",
    "                \n",
    "        modelo = GradientBoostingClassifier(max_depth=mejorParam1)\n",
    "        parametros = 'max_depth:%s' %mejorParam1  \n",
    "        \n",
    "    if(tipo==modeloRegresion.KVecinos):                 \n",
    "        \n",
    "        nombre = \"KVecinos\"     \n",
    "        \n",
    "        # CALCULAMOS EL MEJOR MODELO EN FUNCION DEL NÜMERO DE VECINOS   \n",
    "        mejorParam1 = 0\n",
    "        mejorScoreTree = 0\n",
    "        \n",
    "        for i in range(2,8):\n",
    "            aux = KNeighborsRegressor(n_neighbors=i)  \n",
    "            aux.fit(x_ent,y_ent)\n",
    "            score = aux.score(x_test,y_test)\n",
    "\n",
    "            if(score > mejorScoreTree):\n",
    "                mejorScoreTree = score\n",
    "                mejorParam1 = i        \n",
    "                \n",
    "        modelo = KNeighborsRegressor(n_neighbors=mejorParam1)  \n",
    "        parametros = 'max_depth:%s' %mejorParam1          \n",
    "    \n",
    "    if(tipo==modeloRegresion.XGBClassifier):                 \n",
    "        \n",
    "        nombre = \"XGBClassifier\"     \n",
    "        modelo = xgb.XGBClassifier()  \n",
    "        \n",
    "        '''\n",
    "        param = {}\n",
    "        param['booster'] = 'gbtree'\n",
    "        param['objective'] = 'binary:logistic'\n",
    "        param[\"eval_metric\"] = \"error\"\n",
    "        param['eta'] = 0.3\n",
    "        param['gamma'] = 0\n",
    "        param['max_depth'] = 6\n",
    "        param['min_child_weight']=1\n",
    "        param['max_delta_step'] = 0\n",
    "        param['subsample']= 1\n",
    "        param['colsample_bytree']=1\n",
    "        param['silent'] = 1\n",
    "        param['seed'] = 0\n",
    "        param['base_score'] = 0.5\n",
    "        '''                    \n",
    "        \n",
    "    modelo.fit(x_ent,y_ent)    \n",
    "        \n",
    "    y_pred = modelo.predict(x_test)\n",
    "    \n",
    "    score = accuracy_score(y_test,y_pred)#*100\n",
    "    #score = modelo.score(x_test,y_test)\n",
    "    \n",
    "    reportModelo = classification_report(y_test, y_pred)\n",
    " \n",
    "    resultadoModelo = [nombre, score, parametros] \n",
    "\n",
    "    return resultadoModelo, reportModelo, x_ent, x_test, y_ent, y_test, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerModelosClasificacion(df, nombreColumnaLabel):\n",
    "    \n",
    "    dfResultados = pd.DataFrame(columns=('ALGORITMO','ACCURACY','PARÁMETROS'))  \n",
    "    \n",
    "    start = time.time()\n",
    "    resultadoModelo, reportModelo, x_ent, x_test, y_ent, y_test, y_pred = obtenerModelo(dfFinal, \"PRONOSTICO\", modeloRegresion.SGDClassifier)\n",
    "    dfResultados.loc[len(dfResultados)] = resultadoModelo\n",
    "    print(reportModelo)\n",
    "    print(\"PROCESADO SGDClassifier EN \" + str(time.time() - start) + \" segundos.\")    \n",
    "    \n",
    "    start = time.time()\n",
    "    resultadoModelo, reportModelo, x_ent, x_test, y_ent, y_test, y_pred = obtenerModelo(dfFinal, \"PRONOSTICO\", modeloRegresion.DecisionTreeClassifier)\n",
    "    dfResultados.loc[len(dfResultados)] = resultadoModelo\n",
    "    print(reportModelo)\n",
    "    print(\"PROCESADO DecisionTree EN \" + str(time.time() - start) + \" segundos.\")\n",
    "    \n",
    "    start = time.time()\n",
    "    resultadoModelo, reportModelo, x_ent, x_test, y_ent, y_test, y_pred = obtenerModelo(dfFinal, \"PRONOSTICO\", modeloRegresion.RandomForest)\n",
    "    dfResultados.loc[len(dfResultados)] = resultadoModelo\n",
    "    print(reportModelo)\n",
    "    print(\"PROCESADO RandomForest EN \" + str(time.time() - start) + \" segundos.\")\n",
    "    \n",
    "    start = time.time()    \n",
    "    resultadoModelo, reportModelo, x_ent, x_test, y_ent, y_test, y_pred = obtenerModelo(dfFinal, \"PRONOSTICO\", modeloRegresion.GradientBoostingClassifier)\n",
    "    dfResultados.loc[len(dfResultados)] = resultadoModelo\n",
    "    print(reportModelo)\n",
    "    print(\"PROCESADO GradientBoostingClassifier EN \" + str(time.time() - start) + \" segundos.\")\n",
    "    \n",
    "    start = time.time()    \n",
    "    resultadoModelo, reportModelo, x_ent, x_test, y_ent, y_test, y_pred = obtenerModelo(dfFinal, \"PRONOSTICO\", modeloRegresion.RandomForest)\n",
    "    dfResultados.loc[len(dfResultados)] = resultadoModelo\n",
    "    print(reportModelo)\n",
    "    print(\"PROCESADO RandomForest EN \" + str(time.time() - start) + \" segundos.\")\n",
    "    \n",
    "    start = time.time()    \n",
    "    resultadoModelo, reportModelo, x_ent, x_test, y_ent, y_test, y_pred = obtenerModelo(dfFinal, \"PRONOSTICO\", modeloRegresion.XGBClassifier)\n",
    "    dfResultados.loc[len(dfResultados)] = resultadoModelo\n",
    "    print(reportModelo)\n",
    "    print(\"PROCESADO XGBClassifier EN \" + str(time.time() - start) + \" segundos.\")\n",
    "    \n",
    "    return dfResultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "FUNCIONES DE VISUALIZACION\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pintaDatos(df):\n",
    "\n",
    "    test_size=0.1\n",
    "    split_row = len(df) - int(test_size * len(df))\n",
    "    train_data = df.iloc[:split_row]\n",
    "    test_data = df.iloc[split_row:]\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(16, 9))\n",
    "    ax.plot(train_data.CLOSE, label=\"DATOS DE ENTRENAMIENTO\", linewidth=2)\n",
    "    ax.plot(test_data.CLOSE, label=\"DATOS DE TEST\", linewidth=2)\n",
    "    ax.set_ylabel('PRECIO [XRP]', fontsize=14)\n",
    "    ax.set_title(\"PREPARACION DE DATOS\", fontsize=18)\n",
    "    ax.legend(loc='best', fontsize=18)\n",
    "    \n",
    "def pintaPrecioPrediccion(df):\n",
    "    \n",
    "    split_row = len(dfFinal) - int(0.2 * len(dfFinal))\n",
    "    train_data = dfFinal.iloc[:split_row]\n",
    "    test_data = dfFinal.iloc[split_row:]\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(16, 9))\n",
    "    ax.plot(dfFinal.index, dfFinal[\"CLOSE\"], label=\"PRECIO REAL\", linewidth=2)\n",
    "    ax.plot(test_data.index, test_data[\"CLOSE\"] + y_pred * test_data[\"CLOSE\"] / 100, label=\"PREDICCIÓN\", linewidth=2)\n",
    "    ax.set_ylabel('PRECIO [XRP]', fontsize=14)\n",
    "    ax.set_title(\"COMPARACIÓN DE PRECIO REAL VS PREDICCIÓN\", fontsize=18)\n",
    "    ax.legend(loc='best', fontsize=18)\n",
    "\n",
    "def pintaPorcentajes(y_test,y_pred):\n",
    "    \n",
    "    pylab.rcParams['figure.figsize'] = (30, 20)\n",
    "    plt.plot(y_test,color='lightblue')\n",
    "    plt.plot(y_pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "ENTRENAMIENTO / TEST\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "CON LA SIGUIENTE LLAMADA, PODEMOS OBTENER EL RESULTADO DE TODAS LAS MÉTRICAS ESTUDIADAS PARA CADA UNO DE LOS ALGORITMOS REGRESORES\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      2429\n",
      "          1       1.00      1.00      1.00      2161\n",
      "\n",
      "avg / total       1.00      1.00      1.00      4590\n",
      "\n",
      "PROCESADO SGDClassifier EN 0.26180005073547363 segundos.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98      2429\n",
      "          1       0.96      1.00      0.98      2161\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4590\n",
      "\n",
      "PROCESADO DecisionTree EN 0.6359999179840088 segundos.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      2429\n",
      "          1       1.00      1.00      1.00      2161\n",
      "\n",
      "avg / total       1.00      1.00      1.00      4590\n",
      "\n",
      "PROCESADO RandomForest EN 0.3380000591278076 segundos.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98      2429\n",
      "          1       0.96      1.00      0.98      2161\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4590\n",
      "\n",
      "PROCESADO GradientBoostingClassifier EN 5.039000034332275 segundos.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      2429\n",
      "          1       1.00      1.00      1.00      2161\n",
      "\n",
      "avg / total       1.00      1.00      1.00      4590\n",
      "\n",
      "PROCESADO RandomForest EN 0.33299994468688965 segundos.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98      2429\n",
      "          1       0.96      1.00      0.98      2161\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4590\n",
      "\n",
      "PROCESADO XGBClassifier EN 3.3519999980926514 segundos.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITMO</th>\n",
       "      <th>ACCURACY</th>\n",
       "      <th>PARÁMETROS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.978431</td>\n",
       "      <td>max_depth:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.999564</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.978214</td>\n",
       "      <td>max_depth:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.999564</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.978431</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ALGORITMO  ACCURACY   PARÁMETROS\n",
       "0               SGDClassifier  1.000000             \n",
       "1      DecisionTreeClassifier  0.978431  max_depth:1\n",
       "2                RandomForest  0.999564             \n",
       "3  GradientBoostingClassifier  0.978214  max_depth:1\n",
       "4                RandomForest  0.999564             \n",
       "5               XGBClassifier  0.978431             "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obtenerModelosClasificacion(dfFinal,\"PRONOSTICO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "MÉTODO AUXILIAR PARA EXPORTAR LOS DATOS A UN CSV PARA UTILIZAR EN D3\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfAgrupadoUsuariosAux = agrupaDatos(dfTransacciones, 1440)\n",
    "#dfAgrupadoCSV = dfAgrupadoUsuariosAux[['NUM_T_COMPRA','NUM_T_VENTA','CANTIDAD_COMPRA','CANTIDAD_VENTA']]\n",
    "#dfAgrupadoCSV.to_csv('ficheroD3.csv', header=False, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv\n",
    "#import collections\n",
    "#import pandas as pd\n",
    "\n",
    "pathCSV = \"ficheroD3.csv\"\n",
    "\n",
    "dfAgrupadoUsuariosAux = agrupaDatos(dfTransacciones, 1440)\n",
    "dfAgrupadoCSV = dfAgrupadoUsuariosAux[['NUM_T_COMPRA','NUM_T_VENTA','CANTIDAD_COMPRA','CANTIDAD_VENTA']]\n",
    "\n",
    "x = dfAgrupadoCSV.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "dfAgrupadoCSV = pd.DataFrame(x_scaled)\n",
    "dfAgrupadoCSV = dfAgrupadoCSV*100\n",
    "dfAgrupadoCSV = dfAgrupadoCSV.astype('int')\n",
    "dfAgrupadoCSV.to_csv(pathCSV, header=False, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
